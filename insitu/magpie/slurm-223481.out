*******************************************************
* Performing Post Setup
*******************************************************
*******************************************************
* Formatting HDFS Namenode
*******************************************************
18/07/27 09:56:06 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = catalyst35.llnl.gov/192.168.112.35
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/usr/tce/packages/hadoop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_171
************************************************************/
18/07/27 09:56:06 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
18/07/27 09:56:06 INFO namenode.NameNode: createNameNode [-format]
Formatting using clusterid: CID-43fc79e4-2fdd-4781-8512-21e720c62f44
18/07/27 09:56:06 INFO namenode.FSNamesystem: No KeyProvider found.
18/07/27 09:56:06 INFO namenode.FSNamesystem: fsLock is fair:true
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst36 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst68 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst69 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst116 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst131 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst258 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst268 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO util.HostsFileReader: Adding catalyst273 to the list of included hosts from /tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf/hosts-include
18/07/27 09:56:06 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
18/07/27 09:56:06 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
18/07/27 09:56:06 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
18/07/27 09:56:06 INFO blockmanagement.BlockManager: The block deletion will start around 2018 Jul 27 09:56:06
18/07/27 09:56:06 INFO util.GSet: Computing capacity for map BlocksMap
18/07/27 09:56:06 INFO util.GSet: VM type       = 64-bit
18/07/27 09:56:06 INFO util.GSet: 2.0% max memory 958.5 MB = 19.2 MB
18/07/27 09:56:06 INFO util.GSet: capacity      = 2^21 = 2097152 entries
18/07/27 09:56:06 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
18/07/27 09:56:06 INFO blockmanagement.BlockManager: defaultReplication         = 1
18/07/27 09:56:06 INFO blockmanagement.BlockManager: maxReplication             = 512
18/07/27 09:56:06 INFO blockmanagement.BlockManager: minReplication             = 1
18/07/27 09:56:06 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
18/07/27 09:56:06 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
18/07/27 09:56:06 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
18/07/27 09:56:06 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
18/07/27 09:56:06 INFO namenode.FSNamesystem: fsOwner             = do7 (auth:SIMPLE)
18/07/27 09:56:06 INFO namenode.FSNamesystem: supergroup          = do7
18/07/27 09:56:06 INFO namenode.FSNamesystem: isPermissionEnabled = true
18/07/27 09:56:06 INFO namenode.FSNamesystem: HA Enabled: false
18/07/27 09:56:06 INFO namenode.FSNamesystem: Append Enabled: true
18/07/27 09:56:07 INFO util.GSet: Computing capacity for map INodeMap
18/07/27 09:56:07 INFO util.GSet: VM type       = 64-bit
18/07/27 09:56:07 INFO util.GSet: 1.0% max memory 958.5 MB = 9.6 MB
18/07/27 09:56:07 INFO util.GSet: capacity      = 2^20 = 1048576 entries
18/07/27 09:56:07 INFO namenode.FSDirectory: ACLs enabled? false
18/07/27 09:56:07 INFO namenode.FSDirectory: XAttrs enabled? true
18/07/27 09:56:07 INFO namenode.FSDirectory: Maximum size of an xattr: 16384
18/07/27 09:56:07 INFO namenode.NameNode: Caching file names occuring more than 10 times
18/07/27 09:56:07 INFO util.GSet: Computing capacity for map cachedBlocks
18/07/27 09:56:07 INFO util.GSet: VM type       = 64-bit
18/07/27 09:56:07 INFO util.GSet: 0.25% max memory 958.5 MB = 2.4 MB
18/07/27 09:56:07 INFO util.GSet: capacity      = 2^18 = 262144 entries
18/07/27 09:56:07 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
18/07/27 09:56:07 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
18/07/27 09:56:07 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
18/07/27 09:56:07 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
18/07/27 09:56:07 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
18/07/27 09:56:07 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
18/07/27 09:56:07 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
18/07/27 09:56:07 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
18/07/27 09:56:07 INFO util.GSet: Computing capacity for map NameNodeRetryCache
18/07/27 09:56:07 INFO util.GSet: VM type       = 64-bit
18/07/27 09:56:07 INFO util.GSet: 0.029999999329447746% max memory 958.5 MB = 294.5 KB
18/07/27 09:56:07 INFO util.GSet: capacity      = 2^15 = 32768 entries
18/07/27 09:56:07 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1102132946-192.168.112.35-1532710567065
18/07/27 09:56:07 INFO common.Storage: Storage directory /l/ssd/hdfs/dfs/name has been successfully formatted.
18/07/27 09:56:07 INFO namenode.FSImageFormatProtobuf: Saving image file /l/ssd/hdfs/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression
18/07/27 09:56:07 INFO namenode.FSImageFormatProtobuf: Image file /l/ssd/hdfs/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 335 bytes saved in 0 seconds.
18/07/27 09:56:07 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
18/07/27 09:56:07 INFO util.ExitUtil: Exiting with status 0
18/07/27 09:56:07 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at catalyst35.llnl.gov/192.168.112.35
************************************************************/
*******************************************************
* Post Setup Complete
*******************************************************
*******************************************************
* Magpie General Job Info
*
* Job Nodelist: catalyst[35-36,68-69,116,131,258,268,273]
* Job Nodecount: 9
* Job Timelimit in Minutes: 1440
* Job Name: magpie-hdfs-insitu
* Job ID: 223481
*
*******************************************************
Starting hadoop
Starting namenodes on [catalyst35]
catalyst35: starting namenode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-namenode-catalyst35.out
catalyst116: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst116.out
catalyst131: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst131.out
catalyst68: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst68.out
catalyst258: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst258.out
catalyst273: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst273.out
catalyst268: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst268.out
catalyst69: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst69.out
catalyst36: starting datanode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-datanode-catalyst36.out
Starting secondary namenodes [catalyst35]
catalyst35: starting secondarynamenode, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/hadoop-do7-secondarynamenode-catalyst35.out
starting yarn daemons
starting resourcemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-resourcemanager-catalyst35.out
catalyst36: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst36.out
catalyst68: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst68.out
catalyst116: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst116.out
catalyst69: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst69.out
catalyst258: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst258.out
catalyst268: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst268.out
catalyst273: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst273.out
catalyst131: starting nodemanager, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/yarn-do7-nodemanager-catalyst131.out
Waiting 30 seconds to allows Hadoop daemons to setup
*******************************************************
*
* Hadoop Information
*
* You can view your Hadoop status by launching a web browser and pointing to ...
*
* Yarn Resource Manager: http://catalyst35:8088
*
* Job History Server: http://catalyst35:19888
*
* HDFS Namenode: http://catalyst35:50070
* HDFS DataNode: http://<DATANODE>:50075
*
* HDFS can be accessed directly at:
*
*   hdfs://catalyst35:54310
*
* To access Hadoop directly, you'll want to:
*
*   mrsh catalyst35
*   export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64/"
*   export HADOOP_HOME="/usr/tce/packages/hadoop/hadoop-2.7.3"
*   export HADOOP_CONF_DIR="/tmp/do7/hadoop/magpie-hdfs-insitu/223481/conf"
*
* Then you can do as you please.  For example to interact with the Hadoop filesystem:
*
*   $HADOOP_HOME/bin/hdfs dfs ...
*
* To launch jobs you'll want to:
*
*   $HADOOP_HOME/bin/hadoop jar ...
*
* If running interactively, sourcing
*
* /g/g92/do7/my-job-env
*
* will set most common environment variables for your job.
*
*******************************************************
starting historyserver, logging to /tmp/do7/hadoop/magpie-hdfs-insitu/223481/log/mapred-do7-historyserver-catalyst35.out
User home directory /user/do7 not found, creating it
Starting spark
starting org.apache.spark.deploy.master.Master, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.master.Master-1-catalyst35.out
catalyst116: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst116.out
catalyst131: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst131.out
catalyst68: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst68.out
catalyst258: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst258.out
catalyst268: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst268.out
catalyst273: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst273.out
catalyst36: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst36.out
catalyst69: starting org.apache.spark.deploy.worker.Worker, logging to /tmp/do7/spark/magpie-hdfs-insitu/223481/log/spark-do7-org.apache.spark.deploy.worker.Worker-1-catalyst69.out
Waiting 30 seconds to allow Spark daemons to setup
*******************************************************
*
* Spark Information
*
* You can view your Spark status by launching a web browser and pointing to ...
*
* Spark Master: http://catalyst35:8080
* Spark Worker: http://<WORKERNODE>:8081
* Spark Application Dashboard: http://catalyst35:4040
*
* The Spark Master for running jobs is
*
* spark://catalyst35:7077
*
* To access Spark directly, you'll want to:
*
*   mrsh catalyst35
*   export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64/"
*   export SPARK_HOME="/usr/tce/packages/spark/spark-2.3.0-bin-hadoop2.7"
*   export SPARK_CONF_DIR="/tmp/do7/spark/magpie-hdfs-insitu/223481/conf"
*
* Then you can do as you please.  For example to run a job:
*
*   $SPARK_HOME/bin/spark-submit --class <class> <jar>
*
* If running interactively, sourcing
*
* /g/g92/do7/my-job-env
*
* will set most common environment variables for your job.
*
*******************************************************
*******************************************************
* Entering Magpie interactive mode
*******************************************************
*******************************************************
* Run
*
* mrsh catalyst35 kill -s 10 46994
*
* to exit 'interactive' mode early.
*******************************************************
slurmstepd: error: *** STEP 223481.5 ON catalyst35 CANCELLED AT 2018-07-27T14:12:11 ***
slurmstepd: error: *** JOB 223481 ON catalyst35 CANCELLED AT 2018-07-27T14:12:11 ***
